{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 340 Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "\n",
    "The above points are allocated for following the [homework submission instructions](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Finding similar items\n",
    "\n",
    "For this question we'll be using the [Amazon product data set](http://jmcauley.ucsd.edu/data/amazon/). The author of the data set has asked for the following citations:\n",
    "\n",
    "> Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering.\n",
    "> R. He, J. McAuley.\n",
    "> WWW, 2016.\n",
    "> \n",
    "> Image-based recommendations on styles and substitutes.\n",
    "> J. McAuley, C. Targett, J. Shi, A. van den Hengel.\n",
    "> SIGIR, 2015.\n",
    "\n",
    "We will focus on the \"Patio, Lawn, and Garden\" section. Download the [ratings](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Patio_Lawn_and_Garden.csv) and place the file in the `data` directory with the original filename. Once you do that, the code below should load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1259798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A20DWVV8HML3AW</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1371081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3RVP3YBYYOPRH</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1257984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28XY55TP3Q90O</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1314144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3VZW1BGUQO0V3</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1308268800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0  A2VNYWOPJ13AFP  0981850006     5.0  1259798400\n",
       "1  A20DWVV8HML3AW  0981850006     5.0  1371081600\n",
       "2  A3RVP3YBYYOPRH  0981850006     5.0  1257984000\n",
       "3  A28XY55TP3Q90O  0981850006     5.0  1314144000\n",
       "4  A3VZW1BGUQO0V3  0981850006     5.0  1308268800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"ratings_Patio_Lawn_and_Garden.csv\"\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", filename), \"rb\") as f:\n",
    "    ratings = pd.read_csv(f,names=(\"user\",\"item\",\"rating\",\"timestamp\"))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to construct the user-product matrix `X`. Let's see how big it would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 993490\n",
      "The average rating: 4.006400668350965\n",
      "Number of users: 714791\n",
      "Number of items: 105984\n",
      "Fraction nonzero: 1.3114269915944552e-05\n",
      "Size of full X matrix: 606.05 GB\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"item\", user_key=\"user\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"The average rating:\", np.mean(ratings[\"rating\"]))\n",
    "\n",
    "    d = len(set(ratings[item_key]))\n",
    "    n = len(set(ratings[user_key]))\n",
    "    print(\"Number of users:\", n)\n",
    "    print(\"Number of items:\", d)\n",
    "    print(\"Fraction nonzero:\", len(ratings)/(n*d))\n",
    "    print(\"Size of full X matrix: %.2f GB\" % ((n*d)*8/1e9))\n",
    "\n",
    "    return n,d\n",
    "\n",
    "n,d = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "600 GB! That is way too big. We don't want to create that matrix. On the other hand, we see that we only have about 1 million ratings, which would be around 8 MB ($10^6$ numbers $\\times$ at 8 bytes per double precision floating point number). Much more manageable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_X(ratings,n,d,user_key=\"user\",item_key=\"item\"):\n",
    "    user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(n))))\n",
    "    item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(d))))\n",
    "\n",
    "    user_inverse_mapper = dict(zip(list(range(n)), np.unique(ratings[user_key])))\n",
    "    item_inverse_mapper = dict(zip(list(range(d)), np.unique(ratings[item_key])))\n",
    "\n",
    "    user_ind = [user_mapper[i] for i in ratings[user_key]]\n",
    "    item_ind = [item_mapper[i] for i in ratings[item_key]]\n",
    "\n",
    "    X = sparse_matrix((ratings[\"rating\"], (user_ind, item_ind)), shape=(n,d))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind\n",
    "\n",
    "X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(ratings, n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714791, 105984)\n",
      "993490\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(X.shape) # should be number of users by number of items\n",
    "print(X.nnz)   # number of nonzero elements -- should equal number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947920"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Above: verifying our estimate of 8 MB to store sparse `X`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Find the following items:\n",
    "\n",
    "1. the item with the most reviews\n",
    "2. the item with the most total stars\n",
    "3. the item with the highest average stars\n",
    "\n",
    "Then, find the names of these items by looking them up with the url https://www.amazon.com/dp/ITEM_ID, where `ITEM_ID` is the id of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "url_amazon = \"https://www.amazon.com/dp/%s\"\n",
    "\n",
    "# example:\n",
    "print(url_amazon % 'B00CFM0P7Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For q1 https://www.amazon.com/dp/B000HCLLMM\n"
     ]
    }
   ],
   "source": [
    "#1. With the most reviews\n",
    "q1=item_inverse_mapper[np.argmax(X.getnnz(axis=0))]\n",
    "print('For q1', url_amazon % q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For q2 https://www.amazon.com/dp/B000HCLLMM\n"
     ]
    }
   ],
   "source": [
    "#2. The item with the most total stars\n",
    "X_totalstar=np.sum(X, axis=0) \n",
    "q2=item_inverse_mapper[np.argmax(X_totalstar)]\n",
    "print('For q2', url_amazon % q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For q3 https://www.amazon.com/dp/0981850006\n"
     ]
    }
   ],
   "source": [
    "#3. The item with the highest average stars.\n",
    "X_averagestar=X_totalstar/X.getnnz(axis=0)\n",
    "q3=item_inverse_mapper[np.argmax(X_averagestar)]\n",
    "print('For q3', url_amazon % q3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the following histograms \n",
    "\n",
    "1. The number of ratings per user\n",
    "2. The number of ratings per item\n",
    "3. The ratings themselves\n",
    "\n",
    "For the first two, use\n",
    "```\n",
    "plt.yscale('log', nonposy='clip')\n",
    "``` \n",
    "to put the histograms on a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9JLUOBO9JDXORC9Jjft/uKlq99ONSGcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0957db38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q1\n",
    "plt.hist(X.getnnz(axis=1))#. plt is package, not object. We only can use . once.\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD6pJREFUeJzt3W+MHHd9x/H3pw4OVUBJILRC/lM7\nxYq4BxWEk4PaCqEWBZs0NUWotVWpQK1Y0LpqH1TCiKqCZ6FS+yDCbWSEZVohGzelxVaMXESJQqUU\n4tAANpbhcINydYRNA2mpqqaBbx/sGE7Xu/Pu7a739tf3Szrd7m93Zr5zs/547jtzM6kqJEnt+olJ\nFyBJGi+DXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4GyZdAMBtt91WW7ZsmXQZ\nkjRVnnjiie9U1Suu9b41EfRbtmzhzJkzky5DkqZKkm/18z5bN5LUOINekhpn0EtS4wx6SWqcQS9J\njRt50Cd5Y5LPJ3kwyRtHPX9J0mD6Cvokh5NcTnJ20fiOJBeSzCU50A0X8H3gxcD8aMuVJA2q3z36\nI8COhQNJ1gEHgZ3ADLAnyQzw+araCbwX+ODoSpUkrUZffzBVVY8m2bJoeDswV1UXAZIcA3ZV1de6\n178L3DiiOpe15cDD417Esp66/56JLVuS+jXMX8ZuAJ5e8HweuCvJ24A3A7cAH15u4iT7gH0Amzdv\nHqIMSdJKhgn6LDFWVfVJ4JPXmriqDgGHAGZnZ2uIOiRJKxjmrJt5YNOC5xuBS4PMIMm9SQ4999xz\nQ5QhSVrJMEH/OLAtydYk64HdwIlBZlBVJ6tq38033zxEGZKklfR7euVR4DHgjiTzSfZW1QvAfuA0\ncB44XlXnBlm4e/SSNH79nnWzZ5nxU8Cp1S68qk4CJ2dnZ+9b7TwkSSub6CUQ3KOXpPGbaNDbo5ek\n8fOiZpLUOFs3ktQ4WzeS1DhbN5LUOFs3ktQ4WzeS1DhbN5LUOINekhpnj16SGmePXpIaZ+tGkhpn\n0EtS4wx6SWqcB2MlqXEejJWkxtm6kaTGGfSS1DiDXpIaZ9BLUuMMeklqnKdXSlLjPL1Skhpn60aS\nGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bixBn+SmJE8k+ZVxzF+S1L++gj7J4SSXk5xdNL4jyYUk\nc0kOLHjpvcDxURYqSVqdfvfojwA7Fg4kWQccBHYCM8CeJDNJ3gR8Dfj2COuUJK3SDf28qaoeTbJl\n0fB2YK6qLgIkOQbsAl4C3EQv/P8ryamq+uHIKpYkDaSvoF/GBuDpBc/ngbuqaj9AkncC31ku5JPs\nA/YBbN68eYgyJEkrGSbos8RY/ehB1ZGVJq6qQ0meAe5dv37964aoQ5K0gmHOupkHNi14vhG4NMgM\nvKiZJI3fMEH/OLAtydYk64HdwIlBZuBliiVp/Po9vfIo8BhwR5L5JHur6gVgP3AaOA8cr6pzgyzc\nPXpJGr9+z7rZs8z4KeDUSCuSJI2Ud5iSpMZ5hylJapx79JLUOPfoJalxXqZYkhpn60aSGmfrRpIa\nZ+tGkhpn0EtS4+zRS1Lj7NFLUuNs3UhS4wx6SWqcQS9JjfNgrCQ1zoOxktQ4WzeS1DiDXpIaZ9BL\nUuMMeklqnEEvSY3z9EpJapynV0pS42zdSFLjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMaNPOiTvDrJ\ng0keSvKeUc9fkjSYvoI+yeEkl5OcXTS+I8mFJHNJDgBU1fmqejfw68Ds6EuWJA2i3z36I8COhQNJ\n1gEHgZ3ADLAnyUz32q8C/wh8dmSVSpJWpa+gr6pHgWcXDW8H5qrqYlU9DxwDdnXvP1FVPw/85iiL\nlSQN7oYhpt0APL3g+TxwV5I3Am8DbgROLTdxkn3APoDNmzcPUYYkaSXDBH2WGKuqegR45FoTV9Uh\n4BDA7OxsDVGHJGkFw5x1Mw9sWvB8I3BpkBl49UpJGr9hgv5xYFuSrUnWA7uBE4PMwKtXStL49Xt6\n5VHgMeCOJPNJ9lbVC8B+4DRwHjheVecGWbh79JI0fn316KtqzzLjp1jhgGsf8z0JnJydnb1vtfOQ\nJK3MO0xJUuO8w5QkNc6LmklS42zdSFLjbN1IUuNs3UhS42zdSFLjbN1IUuNs3UhS4wx6SWqcPXpJ\napw9eklqnK0bSWqcQS9JjbNHL0mNs0cvSY2zdSNJjTPoJalxBr0kNc6gl6TGGfSS1DhPr5Skxt0w\nyYVX1Ung5Ozs7H2TrGO1thx4eCLLfer+eyayXEnTydaNJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJ\natxYgj7JW5N8JMmnktw9jmVIkvrTd9AnOZzkcpKzi8Z3JLmQZC7JAYCq+ruqug94J/AbI61YkjSQ\nQfbojwA7Fg4kWQccBHYCM8CeJDML3vJH3euSpAnpO+ir6lHg2UXD24G5qrpYVc8Dx4Bd6fkQ8Omq\n+tLoypUkDWrYHv0G4OkFz+e7sd8D3gS8Pcm7l5owyb4kZ5KcuXLlypBlSJKWM+y1brLEWFXVA8AD\nK01YVYeAQwCzs7M1ZB2SpGUMu0c/D2xa8HwjcKnfib16pSSN37BB/ziwLcnWJOuB3cCJfif25uCS\nNH6DnF55FHgMuCPJfJK9VfUCsB84DZwHjlfVuQHm6R69JI1Z3z36qtqzzPgp4NRqFj7t16OXpGng\nHaYkqXETDXp79JI0fl7UTJIaZ+tGkhpn60aSGmfrRpIaZ+tGkhpn60aSGmfrRpIaZ9BLUuPs0UtS\n4+zRS1Ljhr3xiCZgy4GHJ7bsp+6/Z2LLlrQ69uglqXEGvSQ1zoOxktQ4D8ZKUuNs3UhS4wx6SWqc\nQS9JjTPoJalxBr0kNc7TKyWpcZ5eKUmNs3UjSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGjfyoE9y\ne5KPJnlo1POWJA2ur6BPcjjJ5SRnF43vSHIhyVySAwBVdbGq9o6jWEnS4Prdoz8C7Fg4kGQdcBDY\nCcwAe5LMjLQ6SdLQ+gr6qnoUeHbR8HZgrtuDfx44BuwacX2SpCEN06PfADy94Pk8sCHJy5M8CLw2\nyfuWmzjJviRnkpy5cuXKEGVIklZywxDTZomxqqp/A959rYmr6lCSZ4B7169f/7oh6tB1tOXAwxNZ\n7lP33zOR5UotGGaPfh7YtOD5RuDSIDPwomaSNH7DBP3jwLYkW5OsB3YDJwaZgZcplqTx6/f0yqPA\nY8AdSeaT7K2qF4D9wGngPHC8qs4NsnD36CVp/Prq0VfVnmXGTwGnRlqRJGmkvMOUJDXOO0xJUuPc\no5ekxrlHL0mN8zLFktQ4WzeS1DhbN5LUOFs3ktQ4g16SGmePXpIaZ49ekhpn60aSGmfQS1LjDHpJ\natwwtxIcWpJ7gXtf9apXTbIMTQFvYSitngdjJalxtm4kqXEGvSQ1zqCXpMYZ9JLUOINekhrntW4k\nqXGeXilJjbN1I0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekho38ssUJ7kJ+HPgeeCRqvr4qJchSepf\nX3v0SQ4nuZzk7KLxHUkuJJlLcqAbfhvwUFXdB/zqiOuVJA2o39bNEWDHwoEk64CDwE5gBtiTZAbY\nCDzdve0HoylTkrRafQV9VT0KPLtoeDswV1UXq+p54BiwC5inF/Z9z1+SND7D9Og38OM9d+gF/F3A\nA8CHk9wDnFxu4iT7gH0AmzdvHqIMaXwmdQvD/68mdevGSW7n67HOwwR9lhirqvpP4F3XmriqDgGH\nAGZnZ2uIOiRJKximtTIPbFrwfCNwaZAZePVKSRq/YYL+cWBbkq1J1gO7gRODzMCrV0rS+PV7euVR\n4DHgjiTzSfZW1QvAfuA0cB44XlXnBlm4e/SSNH599eiras8y46eAU6tdeFWdBE7Ozs7et9p5SJJW\n5h2mJKlx3mFKkhrnHzRJUuNs3UhS41I1+b9VSnIF+NYqJ78N+M4Iy7nerH+yrH+yprn+tVD7z1TV\nK671pjUR9MNIcqaqZiddx2pZ/2RZ/2RNc/3TVLs9eklqnEEvSY1rIegPTbqAIVn/ZFn/ZE1z/VNT\n+9T36CVJK2thj16StIKpDvpl7lm7piR5KslXkzyZ5Ew39rIkn0nyje77rd14kjzQrc9Xktw5gXr/\nz/2BV1Nvknd07/9GkndMuP4PJPnXbhs8meQtC157X1f/hSRvXjA+kc9Wkk1JPpfkfJJzSX6/G5+K\nbbBC/VOxDZK8OMkXk3y5q/+D3fjWJF/ofpaf6K7YS5Ibu+dz3etbrrVeE1FVU/kFrAO+CdwOrAe+\nDMxMuq4l6nwKuG3R2J8AB7rHB4APdY/fAnya3k1dXg98YQL1vgG4Ezi72nqBlwEXu++3do9vnWD9\nHwD+cIn3znSfmxuBrd3nad0kP1vAK4E7u8cvBb7e1TkV22CF+qdiG3Q/x5d0j18EfKH7uR4Hdnfj\nDwLv6R7/DvBg93g38ImV1ut6fIaW+prmPfrl7lk7DXYBH+sefwx464Lxv6yefwJuSfLK61lYLX1/\n4EHrfTPwmap6tqq+C3yGRTeXH5dl6l/OLuBYVf13Vf0LMEfvczWxz1ZVPVNVX+oe/we9S4BvYEq2\nwQr1L2dNbYPu5/j97umLuq8Cfgl4qBtf/PO/ul0eAn45SVh+vSZimoN+qXvWrvSBmpQC/j7JE+nd\nJxfgp6vqGej9wwB+qhtfq+s0aL1rcT32d62Nw1fbHqzx+rs2wGvp7VVO3TZYVD9MyTZIsi7Jk8Bl\nev9BfhP4XvXuwbG4lh/V2b3+HPBy1sDPf6FpDvol71l73au4tl+oqjuBncDvJnnDCu+dlnW6arl6\n19p6/AXws8BrgGeAP+3G12z9SV4C/A3wB1X17yu9dYmxia/DEvVPzTaoqh9U1Wvo3R51O/DqFWpZ\nc/UvZZqDfuh71l4PVXWp+34Z+Ft6H5xvX23JdN8vd29fq+s0aL1raj2q6tvdP94fAh/hx79Cr8n6\nk7yIXkh+vKo+2Q1PzTZYqv5p2wYAVfU94BF6Pfpbkly9UdPCWn5UZ/f6zfRahxOvf6FpDvqh71k7\nbkluSvLSq4+Bu4Gz9Oq8ehbEO4BPdY9PAL/VnUnxeuC5q7+uT9ig9Z4G7k5ya/cr+t3d2EQsOs7x\na/S2AfTq392dObEV2AZ8kQl+trr+7keB81X1ZwtemoptsFz907INkrwiyS3d458E3kTvOMPngLd3\nb1v887+6Xd4O/EP1jsYut16TMamjwKP4onfGwdfp9dDeP+l6lqjvdnpH3r8MnLtaI70e3meBb3Tf\nX1Y/PuJ/sFufrwKzE6j5KL1frf+H3l7J3tXUC/w2vQNQc8C7Jlz/X3X1fYXeP8BXLnj/+7v6LwA7\nJ/3ZAn6R3q/4XwGe7L7eMi3bYIX6p2IbAD8H/HNX51ngj7vx2+kF9Rzw18CN3fiLu+dz3eu3X2u9\nJvHlX8ZKUuOmuXUjSeqDQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuP+F/bWdz+3yQvs\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a280d6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q2\n",
    "plt.hist(X.getnnz(axis=0))\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2840e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q3 the rating themselves.\n",
    "#X_array=np.array(X)\n",
    "\n",
    "\n",
    "#X_nnz=X[X!=0].flatten()\n",
    "\n",
    "#print(np.sum(X != 0))\n",
    "#print('world')\n",
    "X_nnz=np.array(X[X!=0]).flatten()\n",
    "#print(type(X_nnz))\n",
    "#print('we did it')\n",
    "#print(X_nnz.shape)\n",
    "#print(X.getnnz(axis=0).shape)\n",
    "plt.hist(X_nnz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Use scikit-learn's [NearestNeighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) object (which uses Euclidean distance by default) to find the 5 items most similar to [Brass Grill Brush 18 Inch Heavy Duty and Extra Strong, Solid Oak Handle](https://www.amazon.com/dp/B00CFM0P7Y). \n",
    "\n",
    "The code block below grabs the row of `X` associated with the grill brush. The mappers take care of going back and forther between the IDs (like `B00CFM0P7Y`) and the indices of the sparse array (0,1,2,...).\n",
    "\n",
    "Note: keep in mind that `NearestNeighbors` is for taking neighbors across rows, but here we're working across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93652\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "print(grill_brush_ind )\n",
    "grill_brush_vec = X[:,grill_brush_ind]\n",
    "\n",
    "print(url_amazon % grill_brush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.          74.24284477  75.14652354  76.51797175  76.51797175\n",
      "  76.51797175]\n",
      "[ 93652 103866 103865  98897  72226 102810]\n",
      "93652\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n",
      "103866\n",
      "https://www.amazon.com/dp/B00IJB5MCS\n",
      "103865\n",
      "https://www.amazon.com/dp/B00IJB4MLA\n",
      "98897\n",
      "https://www.amazon.com/dp/B00EXE4O42\n",
      "72226\n",
      "https://www.amazon.com/dp/B00743MZCM\n",
      "102810\n",
      "https://www.amazon.com/dp/B00HVXQY9A\n"
     ]
    }
   ],
   "source": [
    "nbrs=NearestNeighbors(n_neighbors=6)\n",
    "nbrs.fit(X.T)\n",
    "distances, indices = nbrs.kneighbors(grill_brush_vec.T)\n",
    "                                \n",
    "print(distances[0])\n",
    "print(indices[0])\n",
    "for index in indices[0]:\n",
    "    code=item_inverse_mapper[index]\n",
    "    code_inx = item_mapper[code]\n",
    "    print(index )\n",
    "    code_inx_link = X[:,code_inx]\n",
    "\n",
    "    print(url_amazon % code)\n",
    "    \n",
    "#transpose it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Using cosine similarity instead of Euclidean distance in `NearestNeighbors`, find the 5 products most similar to `B00CFM0P7Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.6987374   0.72171348  0.74965277  0.78953721  0.88109454]\n",
      "[ 93652 103866 103867 103865  98068  98066]\n",
      "93652\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n",
      "103866\n",
      "https://www.amazon.com/dp/B00IJB5MCS\n",
      "103867\n",
      "https://www.amazon.com/dp/B00IJB8F3G\n",
      "103865\n",
      "https://www.amazon.com/dp/B00IJB4MLA\n",
      "98068\n",
      "https://www.amazon.com/dp/B00EF45AHU\n",
      "98066\n",
      "https://www.amazon.com/dp/B00EF3YF0Y\n"
     ]
    }
   ],
   "source": [
    "nbrs=NearestNeighbors(n_neighbors=6,metric='cosine')\n",
    "nbrs.fit(X.T)\n",
    "distances1, indices1 = nbrs.kneighbors(grill_brush_vec.T)\n",
    "                                \n",
    "print(distances1[0])\n",
    "print(indices1[0])\n",
    "for index in indices1[0]:\n",
    "    code=item_inverse_mapper[index]\n",
    "    code_inx = item_mapper[code]\n",
    "    print(index )\n",
    "    code_inx_link = X[:,code_inx]\n",
    "\n",
    "    print(url_amazon % code)\n",
    "    \n",
    "#transpose it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "rubric={reasoning:2}\n",
    "\n",
    "For each of the two metrics, compute the compute the total popularity (total stars) of each of the 5 items and report it. Do the results make sense given what we discussed in class about Euclidean distance vs. cosine similarity? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 105984)\n",
      "[[ 266.  205.    5.    5.    5.]]\n",
      "[[ 266.  438.  205.  311.  513.]]\n"
     ]
    }
   ],
   "source": [
    "X_totalstar=np.sum(X, axis=0) \n",
    "print(X_totalstar.shape)\n",
    "#distances\n",
    "print(X_totalstar[:,indices[0][1:6]])\n",
    "#distances1\n",
    "print(X_totalstar[:,indices1[0][1:6]])\n",
    "#Oh yes it totally makes sense cosine gives us more popular things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6\n",
    "rubric={reasoning:3}\n",
    "\n",
    "PCA gives us an approximation $X \\approx ZW$ where the rows of $Z$ contain a length-$k$ latent feature vectors for each user and the columns of $W$ contain a length-$k$ latent feature vectors for each item.\n",
    "\n",
    "Another strategy for finding similar items is to run PCA and then search for nearest neighbours with Euclidean distance in the latent feature space, which is hopefully more meaningful than the original \"user rating space\". In other words, we run nearest neighbors on the columns of $W$. Using $k=10$ and scikit-learn's [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) to perform the dimensionality reduction, find the 5 nearest neighbours to the grill brush using this method. You can access $W$ via the `components_` field of the `TruncatedSVD` object, after you fit it to the data. \n",
    "\n",
    "Briefly comment on your results.\n",
    "\n",
    "Implementation note: when you call on `NearestNeighbors.kneighbors`, it expects the input to be a 2D array. There's some weirdness here because `X` is a scipy sparse matrix but your `W` will be a dense matrix, and they behave differently in subtle ways. If you get an error like \"Expected 2D array, got 1D array instead\" then this is your problem: a column of `W` is technically a 1D array but a column of `X` has dimension $1\\times n$, which is technically a 2D array. You can take a 1D numpy array and add an extra first dimension to it with `array[None]`.\n",
    "\n",
    "Conceptual note 1: We are using the \"truncated\" rather than full SVD since a full SVD would involve dense $d\\times d$ matrices, which we've already established are too big to deal with. And then we'd only use the first $k$ rows of it anyway. So a full SVD would be both impossible and pointless.\n",
    "\n",
    "Conceptual note 2: as discussed in class, there is a problem here, which is that we're not ignoring the missing entries. You could get around this by optimizing the PCA objective with gradient descent, say using `findMin` from previous assignments. But we're just going to ignore that for now, as the assignment seems long enough as it is (or at least it's hard for me to judge how long it will take because it's new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 105984)\n",
      "93652\n",
      "[  1.29606133e-03  -4.93845791e-06  -1.00760088e-05   2.39874637e-05\n",
      "   2.11183109e-05   1.95354522e-05   5.20837899e-05   1.33473872e-04\n",
      "   2.26275699e-04   3.38682130e-05]\n"
     ]
    }
   ],
   "source": [
    "# run PCA with k=10, TruncatedSVD\n",
    "tsvd=TruncatedSVD(n_components=10)\n",
    "tsvd.fit(X)\n",
    "W=tsvd.components_\n",
    "print(W.shape)\n",
    "# KNN for the matrix W, and find 5 cloest items\n",
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "print(grill_brush_ind )\n",
    "gbvec = W[:,grill_brush_ind]\n",
    "nbrs=NearestNeighbors(n_neighbors=6)\n",
    "nbrs.fit(W.T)\n",
    "print(W[:,93652])\n",
    "distances2, indices2 = nbrs.kneighbors(gbvec[None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.0002518   0.00026866  0.00027467  0.00028331  0.00030547]\n",
      "[93652 18864 19540 13756 31819 58568]\n",
      "https://www.amazon.com/dp/B000W46XSM\n",
      "https://www.amazon.com/dp/B000X9BNG8\n",
      "https://www.amazon.com/dp/B000MVLB8W\n",
      "https://www.amazon.com/dp/B001VNC3Q4\n",
      "https://www.amazon.com/dp/B004WB77L8\n"
     ]
    }
   ],
   "source": [
    "print(distances2[0])\n",
    "print(indices2[0])\n",
    "#code=item_inverse_mapper[indices2[0]]\n",
    "#indices2[0].shape\n",
    "#code_inx = item_mapper[code]\n",
    "#print(indices2[0])\n",
    "#code_inx_link = X[:,code_inx]\n",
    "#print(url_amazon % code)\n",
    "for index in indices2[0][1:]:\n",
    "    code=item_inverse_mapper[index]\n",
    "    print(url_amazon % code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: putting it all together in a CPSC 340 \"mini-project\"\n",
    "rubric={reasoning:25}\n",
    "\n",
    "In this open-ended mini-project, you'll explore the [UCI default of credit card clients data set](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). There are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default payment next month\" in the data. The rest of the columns can be used as features. \n",
    "\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Download the data set and load it in. Since the data comes as an MS Excel file, I suggest using [`pandas.read_excel`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) to read it in. See [Lecture 2](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/lectures/L2.ipynb) for an example of using pandas.\n",
    "2. Perform exploratory data analysis on the data set. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Randomly split the data into train, validation, test sets. The validation set will be used for your experiments. The test set should be saved until the end, to make sure you didn't overfit on the validation set. You are welcome to use scikit-learn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which takes care of both shuffling and splitting. \n",
    "4. Try scikit-learn's [DummyClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) as a baseline model.\n",
    "5. Try logistic regression as a first real attempt. Make a plot of train/validation error vs. regularization strength. What’s the lowest validation error you can get?\n",
    "6. Explore the features, which are described on the UCI site. Explore preprocessing the features, in terms of transforming non-numerical variables, feature scaling, change of basis, etc. Did this improve your results?\n",
    "7. Try 3 other models aside from logistic regression, at least one of which is a neural network. Can you beat logistic regression? (For the neural net(s), the simplest choice would probably be to use scikit-learn's [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), but you are welcome to use any software you wish. )\n",
    "8. Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. I won't make it a strict requirement, but I recommend checking out one of the following (the first two are simple scikit-learn tools, the latter two are much more sophisticated algorithms and require installing new packages): \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)\n",
    "9. Explore feature selection for this problem. What are some particularly relevant and irrelevant features? Can you improve on your original logistic regression model if you first remove some irrelevant features?\n",
    "10. Take your best model overall. Train it on the combined train/validation set and run it on the test set once. Does the test error agree fairly well with the validation error from before? Do you think you’ve had issues with optimization bias? Report your final test error directly in your README.md file as well as in your report.\n",
    "\n",
    "**Submission format:**\n",
    "Your submission should take the form of a \"report\" that includes both code and an explanation of what you've done. You don't have to include everything you ever tried - it's fine just to have your final code - but it should be reproducible. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code.\n",
    "\n",
    "**Assessment:**\n",
    "We plan to grade and fairly leniently. We don't have some secret target accuracy that you need to achieve to get a good grade. You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results. For example, if you write something like, \"And then I noticed the model was overfitting, so I decided to stop using regularization\" - then, well, that's not good. If you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "**And...**\n",
    "This style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-6 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, don't do it out of perfectionism... do it because you're learning and enjoying it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform exploratory data analysis on the data set. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5             ...              BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "0     -2             ...                      0          0          0   \n",
       "1      0             ...                   3272       3455       3261   \n",
       "2      0             ...                  14331      14948      15549   \n",
       "3      0             ...                  28314      28959      29547   \n",
       "4      0             ...                  20940      19146      19131   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0         0       689         0         0         0         0   \n",
       "1         0      1000      1000      1000         0      2000   \n",
       "2      1518      1500      1000      1000      1000      5000   \n",
       "3      2000      2019      1200      1100      1069      1000   \n",
       "4      2000     36681     10000      9000       689       679   \n",
       "\n",
       "   default payment next month  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"default of credit card clients.xls\"\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", filename), \"rb\") as f:\n",
    "    creditcard = pd.read_excel(f,header=1)\n",
    "    \n",
    "creditcard = creditcard.drop(\"ID\", axis=1)\n",
    "creditcard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We glimpse the dataset. We can see lots of variation between features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7788\n",
       "1    0.2212\n",
       "Name: default payment next month, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard['default payment next month'].value_counts(normalize=True) #frequencies of label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77% paid on time and 22% did not paid on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>1.133187</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LIMIT_BAL           SEX     EDUCATION      MARRIAGE           AGE  \\\n",
       "count    30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean    167484.322667      1.603733      1.853133      1.551867     35.485500   \n",
       "std     129747.661567      0.489129      0.790349      0.521970      9.217904   \n",
       "min      10000.000000      1.000000      0.000000      0.000000     21.000000   \n",
       "25%      50000.000000      1.000000      1.000000      1.000000     28.000000   \n",
       "50%     140000.000000      2.000000      2.000000      2.000000     34.000000   \n",
       "75%     240000.000000      2.000000      2.000000      2.000000     41.000000   \n",
       "max    1000000.000000      2.000000      6.000000      3.000000     79.000000   \n",
       "\n",
       "              PAY_0         PAY_2         PAY_3         PAY_4         PAY_5  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      -0.016700     -0.133767     -0.166200     -0.220667     -0.266200   \n",
       "std        1.123802      1.197186      1.196868      1.169139      1.133187   \n",
       "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        8.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "                  ...                  BILL_AMT4      BILL_AMT5  \\\n",
       "count             ...               30000.000000   30000.000000   \n",
       "mean              ...               43262.948967   40311.400967   \n",
       "std               ...               64332.856134   60797.155770   \n",
       "min               ...             -170000.000000  -81334.000000   \n",
       "25%               ...                2326.750000    1763.000000   \n",
       "50%               ...               19052.000000   18104.500000   \n",
       "75%               ...               54506.000000   50190.500000   \n",
       "max               ...              891586.000000  927171.000000   \n",
       "\n",
       "           BILL_AMT6       PAY_AMT1      PAY_AMT2      PAY_AMT3  \\\n",
       "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
       "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
       "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
       "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
       "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
       "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
       "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
       "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
       "\n",
       "            PAY_AMT4       PAY_AMT5       PAY_AMT6  default payment next month  \n",
       "count   30000.000000   30000.000000   30000.000000                30000.000000  \n",
       "mean     4826.076867    4799.387633    5215.502567                    0.221200  \n",
       "std     15666.159744   15278.305679   17777.465775                    0.415062  \n",
       "min         0.000000       0.000000       0.000000                    0.000000  \n",
       "25%       296.000000     252.500000     117.750000                    0.000000  \n",
       "50%      1500.000000    1500.000000    1500.000000                    0.000000  \n",
       "75%      4013.250000    4031.500000    4000.000000                    0.000000  \n",
       "max    621000.000000  426529.000000  528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 30,000 data. We can see summary statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25     50000.0\n",
       "0.50    140000.0\n",
       "0.75    240000.0\n",
       "Name: LIMIT_BAL, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard['LIMIT_BAL'].quantile((0.25,0.5,0.75))# quantiles of the money people spent on the moth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quantiles of the money people spent on the month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'frequency')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1851ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(creditcard['AGE'])\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of the ages of credit card users. People in their 30's are the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a18545128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEKCAYAAABQRFHsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18528b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"EDUCATION\",y=\"LIMIT_BAL\",data=creditcard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the trands of the amount of spending money regarding the education level of the people. (As one of the awesome TAs of 340 said I don't need to clean the data and because of the lack of time, I didn't clean the data.) \n",
    "\n",
    "It is seen that lower education level indicates lower spend of the money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3. Randomly split the data into train, validation, test sets. The validation set will be used for your experiments. The test set should be saved until the end, to make sure you didn't overfit on the validation set. You are welcome to use scikit-learn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which takes care of both shuffling and splitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 23)\n",
      "(18000,)\n",
      "(6000, 23)\n",
      "(6000,)\n",
      "(6000, 23)\n",
      "(6000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25951</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46174</td>\n",
       "      <td>47193</td>\n",
       "      <td>48105</td>\n",
       "      <td>49327</td>\n",
       "      <td>1723</td>\n",
       "      <td>2393</td>\n",
       "      <td>2090</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2106</td>\n",
       "      <td>8538</td>\n",
       "      <td>390</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10644</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15617</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20818</td>\n",
       "      <td>9864</td>\n",
       "      <td>3957</td>\n",
       "      <td>2205</td>\n",
       "      <td>18056</td>\n",
       "      <td>4065</td>\n",
       "      <td>1058</td>\n",
       "      <td>3976</td>\n",
       "      <td>2216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9847</th>\n",
       "      <td>360000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14250</td>\n",
       "      <td>13780</td>\n",
       "      <td>15077</td>\n",
       "      <td>14009</td>\n",
       "      <td>3005</td>\n",
       "      <td>3024</td>\n",
       "      <td>4004</td>\n",
       "      <td>4008</td>\n",
       "      <td>3008</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "25951      90000    2          2         1   48      0      0      0      0   \n",
       "3540      100000    2          2         1   40      1      2      2     -1   \n",
       "15617     200000    2          2         2   26     -2     -2     -2     -2   \n",
       "24137     150000    1          0         2   28      0      0      0      0   \n",
       "9847      360000    1          1         1   46      0      0      0      0   \n",
       "\n",
       "       PAY_5    ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "25951      0    ...         46174      47193      48105      49327      1723   \n",
       "3540       0    ...         -2106       8538        390        150         0   \n",
       "15617     -2    ...             0          0          0          0         0   \n",
       "24137     -1    ...         20818       9864       3957       2205     18056   \n",
       "9847       0    ...         14250      13780      15077      14009      3005   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "25951      2393      2090      2000      2000      1803  \n",
       "3540          0     10644         0       150       780  \n",
       "15617         0         0         0         0         0  \n",
       "24137      4065      1058      3976      2216         0  \n",
       "9847       3024      4004      4008      3008      2024  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(creditcard.drop('default payment next month',1), creditcard['default payment next month'], test_size=0.2, random_state=0)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train1, y_train1, test_size=0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data set has 18,000 data and validation data set has 6000 data. Test dataset also has 600 data. We can see that training dataset is randomly chosed by looking at the index of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Try scikit-learn's [DummyClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) as a baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline error is 0.221666666667\n"
     ]
    }
   ],
   "source": [
    "#Try scikit-learn's DummyClassifier as a baseline model.\n",
    "dummy = DummyClassifier(strategy='most_frequent',random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "#dummy.predict(X_test)\n",
    "y_predict=dummy.predict(X_validation)\n",
    "print(\"Baseline error is\",np.mean(y_predict!=y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline error is as follows. We aim to get lower validation error than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Try logistic regression as a first real attempt. Make a plot of train/validation error vs. regularization strength. What’s the lowest validation error you can get?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIMEAAIogwQAAiiDBAACKIMEAAIq4AqWeqNLC/hVOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a202d5860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the smallest validation error is 0.221833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22183333333333333]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try logistic regression as a first real attempt. \n",
    "#Make a plot of train/validation error vs. regularization strength. \n",
    "#What’s the lowest validation error you can get?\n",
    "\n",
    "r=np.arange(-1,5,0.1)\n",
    "R=10**r\n",
    "train_error=list()\n",
    "validation_error=list()\n",
    "#print(R)\n",
    "for i in R:\n",
    "    logit=LogisticRegression(penalty='l2',C=1/i, random_state=42)\n",
    "    logit.fit(X_train,y_train)\n",
    "    train_predict=logit.predict(X_train)\n",
    "    validation_predict=logit.predict(X_validation)\n",
    "    train_error.append([np.mean(train_predict != y_train)])\n",
    "    validation_error.append([np.mean(validation_predict != y_validation)])\n",
    "\n",
    "plt.plot(R,train_error,lw=2,label=\"training error\")\n",
    "plt.plot(R,validation_error,lw=2,label=\"validation error\")\n",
    "\n",
    "plt.xlabel('regularization strength')\n",
    "plt.ylabel('classification error')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "np.min(validation_error)\n",
    "print(\"the smallest validation error is %f\" %np.min(validation_error))\n",
    "validation_error[np.argmin(validation_error)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the regularization get stronger, there is no such change which makes sence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Explore the features, which are described on the UCI site. Explore preprocessing the features, in terms of transforming non-numerical variables, feature scaling, change of basis, etc. Did this improve your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019483</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.121232</td>\n",
       "      <td>0.167596</td>\n",
       "      <td>-0.234638</td>\n",
       "      <td>-0.146024</td>\n",
       "      <td>-0.178269</td>\n",
       "      <td>-0.178676</td>\n",
       "      <td>-0.187214</td>\n",
       "      <td>-0.196891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706651</td>\n",
       "      <td>-0.543812</td>\n",
       "      <td>-0.660341</td>\n",
       "      <td>-0.657411</td>\n",
       "      <td>-0.336985</td>\n",
       "      <td>-0.242528</td>\n",
       "      <td>0.306270</td>\n",
       "      <td>-0.303632</td>\n",
       "      <td>-0.306407</td>\n",
       "      <td>-0.254875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676676</td>\n",
       "      <td>-0.676402</td>\n",
       "      <td>-0.666729</td>\n",
       "      <td>-0.659927</td>\n",
       "      <td>-0.336985</td>\n",
       "      <td>-0.242528</td>\n",
       "      <td>-0.296656</td>\n",
       "      <td>-0.303632</td>\n",
       "      <td>-0.316072</td>\n",
       "      <td>-0.299086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380374</td>\n",
       "      <td>-0.523220</td>\n",
       "      <td>-0.601913</td>\n",
       "      <td>-0.622935</td>\n",
       "      <td>0.735553</td>\n",
       "      <td>-0.078597</td>\n",
       "      <td>-0.236726</td>\n",
       "      <td>-0.055219</td>\n",
       "      <td>-0.173297</td>\n",
       "      <td>-0.299086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473856</td>\n",
       "      <td>-0.462406</td>\n",
       "      <td>-0.419767</td>\n",
       "      <td>-0.424908</td>\n",
       "      <td>-0.158486</td>\n",
       "      <td>-0.120578</td>\n",
       "      <td>-0.069851</td>\n",
       "      <td>-0.053219</td>\n",
       "      <td>-0.122269</td>\n",
       "      <td>-0.184365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  \\\n",
       "0    2          2         1   48      0      0      0      0      0      0   \n",
       "1    2          2         1   40      1      2      2     -1      0     -1   \n",
       "2    2          2         2   26     -2     -2     -2     -2     -2     -2   \n",
       "3    1          0         2   28      0      0      0      0     -1     -1   \n",
       "4    1          1         1   46      0      0      0      0      0      0   \n",
       "\n",
       "     ...     BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0    ...     -0.019483   0.056481   0.121232   0.167596 -0.234638 -0.146024   \n",
       "1    ...     -0.706651  -0.543812  -0.660341  -0.657411 -0.336985 -0.242528   \n",
       "2    ...     -0.676676  -0.676402  -0.666729  -0.659927 -0.336985 -0.242528   \n",
       "3    ...     -0.380374  -0.523220  -0.601913  -0.622935  0.735553 -0.078597   \n",
       "4    ...     -0.473856  -0.462406  -0.419767  -0.424908 -0.158486 -0.120578   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0 -0.178269 -0.178676 -0.187214 -0.196891  \n",
       "1  0.306270 -0.303632 -0.306407 -0.254875  \n",
       "2 -0.296656 -0.303632 -0.316072 -0.299086  \n",
       "3 -0.236726 -0.055219 -0.173297 -0.299086  \n",
       "4 -0.069851 -0.053219 -0.122269 -0.184365  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "indc = np.append(0, np.arange(11, 23))\n",
    "df = X_train.iloc[:, indc]\n",
    "df_valid = X_validation.iloc[:, indc]\n",
    "names_df = list(df.columns.values)\n",
    "names_mapper = dict(zip(list(range(len(indc))), names_df))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df)).rename(columns = names_mapper)\n",
    "df_valid_scaled = pd.DataFrame(scaler.transform(df_valid)).rename(columns = names_mapper)\n",
    "\n",
    "df_train_rest = X_train.iloc[:, 1:11].reset_index(drop=True)\n",
    "df_train_rest.set_index(np.arange(len(X_train)))\n",
    "df_valid_rest = X_validation.iloc[:, 1:11].reset_index(drop=True)\n",
    "df_valid_rest.set_index(np.arange(len(X_validation)))\n",
    "\n",
    "X_train1 = pd.concat([df_train_rest, df_train_scaled], axis=1)\n",
    "X_validation1 = pd.concat([df_valid_rest, df_valid_scaled], axis=1)\n",
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the mean and standard deviation of training dataset, I normalized the training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAEKCAYAAABDpWzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20223160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the smallest validation error is 0.194833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r=np.arange(-1,5,0.1)\n",
    "R=10**r\n",
    "train_error=list()\n",
    "validation_error=list()\n",
    "#print(R)\n",
    "for i in R:\n",
    "    logit=LogisticRegression(penalty='l1',C=i,random_state=42)\n",
    "    logit.fit(X_train1,y_train)\n",
    "    train_predict=logit.predict(X_train1)\n",
    "    validation_predict=logit.predict(X_validation1)\n",
    "    train_error.append([np.mean(train_predict != y_train)])\n",
    "    validation_error.append([np.mean(validation_predict != y_validation)])\n",
    "\n",
    "plt.plot(r,train_error,lw=2,label=\"training error\")\n",
    "plt.plot(r,validation_error,lw=2,label=\"validation error\")\n",
    "\n",
    "plt.xlabel('regularization strength')\n",
    "plt.ylabel('classification error')\n",
    "plt.legend(bbox_to_anchor=(1.05,1),loc=2,borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "print(\"the smallest validation error is %f\" %np.min(validation_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error is decreased. It is meaningful to normalized the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Try 3 other models aside from logistic regression, at least one of which is a neural network. Can you beat logistic regression? (For the neural net(s), the simplest choice would probably be to use scikit-learn's [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), but you are welcome to use any software you wish. )\n",
    "\n",
    "the smallest validation error is 0.1948, which is the new baseline. \n",
    "\n",
    "I begin with Neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.186333333333\n"
     ]
    }
   ],
   "source": [
    "# Neural network \n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train1,y_train)\n",
    "y_pred = clf.predict(X_validation1)\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is bigger error than logit model's one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.184833333333\n"
     ]
    }
   ],
   "source": [
    "#Random forest \n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train1, y_train)\n",
    "# Use the forest's predict method on the test data\n",
    "y_pred = rf.predict(X_validation1)\n",
    "# Calculate the absolute errors\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is smaller error than logit model's one. Random forest can beat logisit regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.1855\n"
     ]
    }
   ],
   "source": [
    "#Support Vector machine\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC()\n",
    "model.fit(X_train1, y_train)\n",
    "y_pred=model.predict(X_validation1)\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly bigger error than logit model's one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. I won't make it a strict requirement, but I recommend checking out one of the following (the first two are simple scikit-learn tools, the latter two are much more sophisticated algorithms and require installing new packages): \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest: hyperparameters optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A suggested maximum dept is 3\n",
      "A suggested maximum number of feature is 9\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "random_search.fit(X_train1, y_train)\n",
    "\n",
    "print(\"A suggested maximum dept is\",random_search.best_estimator_.max_depth)\n",
    "print(\"A suggested maximum number of feature is\",random_search.best_estimator_.max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.1815\n"
     ]
    }
   ],
   "source": [
    "#Random forest \n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42, max_depth=3, max_features=9)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train1, y_train)\n",
    "# Use the forest's predict method on the test data\n",
    "y_pred = rf.predict(X_validation1)\n",
    "# Calculate the absolute errors\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparameter optimization, we have a little bit smaller validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network tuning: alpha and activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00001\n"
     ]
    }
   ],
   "source": [
    "#Neural network tuning: regularization alpha\n",
    "param_dist = {\"alpha\":  np.arange(1e-5,1e1,1)\n",
    "              }\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist)\n",
    "\n",
    "\n",
    "random_search.fit(X_train1, y_train)\n",
    "\n",
    "print(random_search.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.193\n"
     ]
    }
   ],
   "source": [
    "# Neural network \n",
    "clf = MLPClassifier(alpha=1.00001)\n",
    "clf.fit(X_train1,y_train)\n",
    "y_pred = clf.predict(X_validation1)\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My neural network is better than logit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector classification: Hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a suggested hyperparameter  1.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dist = {\"C\": np.arange(0.001,3,1)}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = GridSearchCV(model, param_grid=param_dist)\n",
    "random_search.fit(X_train1, y_train)\n",
    "\n",
    "print(\"a suggested hyperparameter \",random_search.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.1855\n"
     ]
    }
   ],
   "source": [
    "#Support Vector machine\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC(C=1.001)\n",
    "model.fit(X_train1, y_train)\n",
    "y_pred=model.predict(X_validation1)\n",
    "print(\"The validation error is\",np.mean(y_pred!=y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error of SVC hasn't changed much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Explore feature selection for this problem. What are some particularly relevant and irrelevant features? Can you improve on your original logistic regression model if you first remove some irrelevant features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.190444444444\n",
      "0.195333333333\n",
      "['PAY_3' 'BILL_AMT2' 'BILL_AMT3' 'PAY_AMT5']\n"
     ]
    }
   ],
   "source": [
    "logit=LogisticRegression(penalty='l1',C=0.07,random_state=42)\n",
    "logit.fit(X_train1,y_train)\n",
    "train_predict=logit.predict(X_train1)\n",
    "validation_predict=logit.predict(X_validation1)\n",
    "train_error=np.mean(train_predict != y_train)\n",
    "validation_error=np.mean(validation_predict != y_validation)\n",
    "\n",
    "print(train_error)\n",
    "print(validation_error)\n",
    "\n",
    "print(X_validation.columns.values[np.where(logit.coef_==0)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error is 0.193167\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "X_train_new=X_train1.drop(['PAY_3', 'BILL_AMT2', 'BILL_AMT3', 'PAY_AMT5'],axis=1)\n",
    "X_validation_new=X_validation1.drop(['PAY_3', 'BILL_AMT2', 'BILL_AMT3', 'PAY_AMT5'],axis=1)\n",
    "\n",
    "logit2=LogisticRegression(C=0.1)\n",
    "logit2.fit(X_train_new,y_train)\n",
    "y_pred_new=logit2.predict(X_train_new)\n",
    "training_error_new=np.mean(y_train!=y_pred_new)\n",
    "\n",
    "y_val_pred_new=logit2.predict(X_validation_new)\n",
    "validation_error_new=np.mean(y_validation!=y_val_pred_new)\n",
    "\n",
    "print(\"The validation error is %f\" %validation_error_new)\n",
    "print(X_validation.columns.values[np.where(logit2.coef_==0)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing some irrelavant features doesn't improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Take your best model overall. Train it on the combined train/validation set and run it on the test set once. Does the test error agree fairly well with the validation error from before? Do you think you’ve had issues with optimization bias? Report your final test error directly in your README.md file as well as in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is 0.283666666667\n"
     ]
    }
   ],
   "source": [
    "X_frame=[X_train,X_validation]\n",
    "y_frame=[y_train,y_validation]\n",
    "X_combined=pd.concat(X_frame, axis=0)\n",
    "y_combined=pd.concat(y_frame, axis=0)\n",
    "\n",
    "\n",
    "indc = np.append(0, np.arange(11, 23))\n",
    "df = X_combined.iloc[:, indc]\n",
    "df_test = X_test.iloc[:, indc]\n",
    "names_df = list(df.columns.values)\n",
    "names_mapper = dict(zip(list(range(len(indc))), names_df))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_combined_scaled = pd.DataFrame(scaler.transform(df)).rename(columns = names_mapper)\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test)).rename(columns = names_mapper)\n",
    "\n",
    "df_combined_rest = X_combined.iloc[:, 1:11].reset_index(drop=True)\n",
    "df_combined_rest.set_index(np.arange(len(X_combined)))\n",
    "df_test_rest = X_validation.iloc[:, 1:11].reset_index(drop=True)\n",
    "df_test_rest.set_index(np.arange(len(X_test)))\n",
    "\n",
    "X_final_train = pd.concat([df_combined_rest, df_combined_scaled], axis=1)\n",
    "X_final_test = pd.concat([df_test_rest, df_test_scaled], axis=1)\n",
    "X_final_train.head()\n",
    "\n",
    "y_pred = rf.predict(X_final_test)\n",
    "# Calculate the absolute errors\n",
    "print(\"The test error is\",np.mean(y_pred!=y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the test error agree fairly well with the validation error from. \n",
    "I think I’ve had huge issues with optimization bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Very short answer questions\n",
    "rubric={reasoning:7}\n",
    "\n",
    "1. Why is it difficult for a standard collaborative filtering model to make good predictions for new items?\n",
    "2. Consider a fully connected neural network with layer sizes (10,20,20,5); that is, the input dimensionality is 10, there are two hidden layers each of size 20, and the output dimensionality is 5. How many parameters does the network have, including biases?\n",
    "3. Why do we need nonlinear activation functions in neural networks?\n",
    "4. Assuming we could globally minimize the neural network objectve, how does the depth of a neural network affect the fundamental trade-off?\n",
    "5. List 3 forms of regularization we use to prevent overfitting in neural networks.\n",
    "6. Assuming we could globally minimize the neural network objectve, how would the size of the filters in a convolutational neural network affect the fundamental trade-off?\n",
    "7. Why do people say convolutional neural networks just a special case of a fully-connected (regular) neural networks? What does this imply about the number of learned parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. The model is for unsupervised learning given a label matrix. We only have a matrix Y which is about users and ratings/items. We can learn about each user/movie, but can't predict on new user/movies.\n",
    "2. For the first layer, 20 by 11 W_1 matrix is needed. For the second layer, 21 by 20 W_2 matrix needed. Finally, for the multiclass linear classification, 5 by 21 V matrix is needed. Thus 220+420+105= 745 parameters are needed.\n",
    "3. If not, neural networks is just linear regression that we learned at the first time.\n",
    "4. (What is neural network objective?) If the depth of a neural network is deeper then we have lower training error but the approximation error will increase.\n",
    "5. Standard regularization, Early stopping, and Dropout.\n",
    "6. If the size of a neural network is bigger then we have lower training error but the approximation error will increase.\n",
    "7. Because the convolutional filter is just a sparse W matrix. It imply the learned parameters are drastically smaller.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
